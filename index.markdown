---
layout: default
---

## About Me

I am a PhD candidate at NYU Courant Institute of Mathematical Sciences, [CILVR group](https://wp.nyu.edu/cilvr/),
advised by [Rajesh Ranganath](https://cims.nyu.edu/~rajeshr/) and 
[Thomas Wies](https://cs.nyu.edu/wies/). I work on causal inference, deep generative models,
and machine learning for health. I'm also a part of the [STAT research group](https://cds.nyu.edu/stat/) at the NYU Center for Data Science.

I will generally be looking to postdocs + jobs in the fall. Feel free to reach out about this!

<!--
I work on survival analysis, 
causal inference, and machine learning for health.
-->

<!--
I work on survival analysis, 
causal inference, and representation learning problems with a focus on machine learning for health.
-->

## News


* (Summer-Fall 2024) student researcher at Google DeepMind NYC with [Will Grathwohl](https://www.cs.toronto.edu/~wgrathwohl/)!

* (Spring 2024) honored to receive the Henning Biermann Prize for teaching by a PhD student at NYU Courant!

* (Spring 2024) accepted to ICML 2024: Denoising Score Matching For Nonlinear Diffusion Processes (coming soon)! with Raghav Singhal and
Rajesh Ranganath.

* (Spring 2024) accepted to ICML 2024 (**spotlight paper**): [Stochastic interpolants with data-dependent couplings](https://arxiv.org/abs/2310.03725) ! 
with Michael Albergo, Nick Boffi, Rajesh Ranganath, and Eric Vanden-Eijnden! This work is on choosing data-dependent base distributions for continuous-time flows!

* (Spring 2024) accepted to ICML 2024: [probabilistic forecasting with stochastic interpolants and Föllmer processes](https://arxiv.org/abs/2403.13724)! with Yifan Chen, Mengjian Hua, Michael S. Albergo, Nicholas M. Boffi, and Eric Vanden-Eijnden.

<!--glad to help out on the survival analysis / estimation side of things on-->
* (Spring 2024) accepted to European Heart Journal, Acute Cardiovascular Care: 
[A dynamic risk score for early prediction of cardiogenic shock using machine learning](https://academic.oup.com/ehjacc/advance-article/doi/10.1093/ehjacc/zuae037/7633877)
Also available on [arxiv](https://arxiv.org/abs/2303.12888). 

<!--glad to help out on the survival analysis / estimation side of things on -->
* (Feb 2024) accepted to Journals of the American College of Cardiology, Clinical Electrophysiology:
[QTNet: Predicting Drug-Induced QT Prolongation with Artificial Intelligence-Enabled Electrocardiograms](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4554451)

* (Jan 2024) [Scalable Interpolant Transformers](https://arxiv.org/abs/2401.08740)! 
<!-- A family of generative models built on Diffusion Transformers, but with a flexible stochastic interpolant
process replacing the score based diffusion. Stable to train, performs well at each model size, 
and many choices for sampling! -->

<!-- * (Fall 2023) glad to take part in the Flatiron Institute’s upcoming second workshop on Measure Transport, Sampling, and Diffusions! -->
* (Fall 2023) taking part @ Flatiron Institute’s upcoming second workshop on Measure Transport, Sampling, and Diffusions!


<!--* (Fall 2023) glad to teach a lecture about diffusions + flows for the NYU course, Inference and Representations, with prof. Yoav Wald.-->
* (Fall 2023) lecture on diffusions + flows @ NYU course, Inference and Representations

<!--* (Fall 2023) glad to talk about diffusions + flows at 
the [Decisions, Risk and Operations](https://business.columbia.edu/faculty/divisions/dro) ML reading group at Columbia, organized by Hongseok Namkoong, Kelly Zhang, Tiffany Cai, and others!-->

* (Fall 2023) talk on diffusions + flows @ [Decisions, Risk and Operations](https://business.columbia.edu/faculty/divisions/dro) ML reading group at Columbia, organized by Hongseok Namkoong!

* (Summer 2023)  We are running the second iteration of the workshop on Spurious Correlations, Invariance, and Stability at ICML 2023! 

* (Spring 2023) accepted to ICLR 2023: [Where to Diffuse, How to Diffuse, and How to Get Back: Automated Learning for Multivariate Diffusions](https://arxiv.org/abs/2302.07261) 

<!-- * (Fall 2022) glad to give a guest lecture on diffusions with my collaborator Raghav Singhal, at Alfredo and Yann's deep learning class at NYU-->
* (Fall 2022) lecture on diffusions @ Yann LeCun's deep learning course at NYU!

<!-- * (Fall 2022) glad to give a talk at the Flatiron Institute's [workshop on Sampling, Transport, and Diffusions](https://sites.google.com/view/sampling-transport-diffusions/home)!-->
* (Fall 2022) talk on diffusions @ the Flatiron Institute's [workshop on Sampling, Transport, and Diffusions](https://sites.google.com/view/sampling-transport-diffusions/home)!

* (Summer 2022) excited to be co-organizing the [ICML Workshop on Spurious Correlations, Invariance, and Stability](https://sites.google.com/view/scis-workshop/home)!

* (Summer 2022) accepted to Machine Learning for Healthcare 2022: [Survival Mixture Density Networks](https://arxiv.org/pdf/2208.10759.pdf)

* (Summer 2022) glad to continue at Apple Health AI for the summer!

* (Spring 2022) accepted to CLeaR (Causal Learning and Reasoning) 2022: [Learning Invariant Representations with Missing Data](https://arxiv.org/pdf/2112.00881.pdf) (full version)

* (Fall 2021) accepted to NeurIPS 2021 DistShift Workshop: [Learning Invariant Representations with Missing Data](https://arxiv.org/pdf/2112.00881.pdf) 
Work done as part of my internship at Apple Health AI.

* (Fall 2021) selected as a recipient of the NeurIPS 2021 Outstanding Reviewer Award. Glad to be a part of it!

* (Fall 2021) accepted to NeurIPS 2021: [Inverse-Weighted Survival Games](https://arxiv.org/pdf/2111.08175.pdf)

* (Summer 2021) working with Apple's Health AI team this summer supervised by [Andy Miller](https://andymiller.github.io/) and team!

<!--
* Spring 2021: some work on games for training survival models in submission! Work by myself\*, Xintian Han\*, Aahlad Puli, Thomas Wies, Adler J. Perotte, and Rajesh Ranganath.
-->
	
* (Spring 2021) accepted to ICML 2021: [Understanding Failures in Out-of-Distribution Detection with Deep Generative Models](https://arxiv.org/pdf/2107.06908.pdf) (full version)

* (Spring 2021) accepted to RobustML workshop @ ICLR 2021 [Understanding Out-of-Distribution Detection with Deep Generative Models](https://sites.google.com/connect.hku.hk/robustml-2021/accepted-papers/paper-045) 

* (Fall 2020) I qualified! Upgrade from Student to Candidate. 

* (Fall 2020) after some time away from harvard cs, happy to help out Prof [Nada Amin](https://namin.seas.harvard.edu/people/nada-amin) with the harvard AI/PL seminar 

* (Fall 2020) the deep learning course I TA'ed in spring 2020 for [Yann LeCun](http://yann.lecun.com/) and Alfredo Canziani is now up on [Alf's github page](https://atcold.github.io/pytorch-Deep-Learning/), check out all of Alf's wonderful teaching materials and thanks to students for your notetaking

* (Fall 2020) accepted to NeurIPS 2020: [X-CAL: Explicit Calibration for Survival Analysis](https://arxiv.org/pdf/2101.05346.pdf)

* (Summer 2019) I'm working in [Emtiyaz Khan's](https://emtiyaz.github.io/) Approximate Bayesian Inference group at [RIKEN AIP](https://aip.riken.jp/) in Tokyo!

* (2018) MacCracken Fellow, NYU Graduate School of Arts and Sciences, Five years of PhD funding.


## mentoring
- Abhipsha Das (Master's Thesis at NYU, 2024, on diffusions for text)
- Shraddha Jain (current Master's student, 2024, research on VAEs)
- Nina Mortensen (Masters Thesis at NYU, 2024, research on VAEs, now at Fauna Robotics)
- mentor for [Women in Data Science Datathon](https://www.widscambridge.org/datathon), Cambridge, 2021. 

## Courses I've TA'ed/TF'ed:
- NYU, CSCI-GA.2565: Machine Learning. Prof: Rajesh Ranganath. Spring 2022.
- NYU, CSCI-GA.2565: Machine Learning. Prof: Rajesh Ranganath. Spring 2021.
- NYU, CSCI-GA.2572: Deep Learning. Prof: Yann LeCun. Spring 2020.
- NYU, CSCI-GA.2565: Machine Learning. Prof: Rajesh Ranganath. Fall 2019.
- Harvard, CS 181: Machine Learning. Profs: Finale Doshi-Velez and David Parkes. Spring 2021.
- Harvard, CS 252: Programming Languages and Artificial Intelligence. Prof: Nada Amin. Fall 2020.
- Harvard, CS 181: Machine Learning. Prof: Finale Doshi-Velez. Spring 2018.
- Harvard, CS 281: Advanced Machine Learning. Prof: Sasha Rush. Fall 2017.
- Harvard, CS 121: Intro to Theoretical CS. Profs: Boaz Barak and Salil Vadhan. Fall 2017.
- Harvard, CS 181: Machine Learning. Profs: David Parkes and Sasha Rush. Spring 2017.
- Harvard, CS 61: Systems Programming and Machine Organization. Profs: Margo Seltzer and Eddie Kohler. Fall 2016.

## Conferences I usually review for 
- NeurIPS
- ICML
- ICLR
- AAAI
- AISTATS
- CLeaR
- misc workshops

## In a previous life

I was a research assistant and teaching fellow in the computer science department 
at [Harvard SEAS](https://www.seas.harvard.edu/).
I am still an on/off TF for the 
[harvard undergrad ML course](https://harvard-ml-courses.github.io/cs181-web/).
Between Harvard and NYU, I worked with the 
[CoCoSci](http://cocosci.mit.edu/) group at 
[MIT BCS](https://bcs.mit.edu/).
Previous to that, I studied music composition, improvisation, and theory 
at New England Conservatory with 
[Anthony Coleman](https://en.wikipedia.org/wiki/Anthony_Coleman),
[Stratis Minakakis](https://www.stratisminakakis.info) 
and [Ran Blake](https://ranblake.com/).
I am still involved with music and rehearse with
[Gamelan Kusuma Laras](https://kusumalaras.org/) a classical Javanese ensemble 
that performs the repetoire of the courts of Central Java.

<!--
<p>
Mark Goldstein<br>
<a href="https://en.wikipedia.org/wiki/Courant_Institute_of_Mathematical_Sciences">Courant Institute of Mathematical Sciences</a><br>
pronouns: he/him/his <br>
</p>
-->

  <!---
    I'm curious about how we can understand phenomena in and around us
    (e.g. in healthcare, environment, art)
    with a mix of mechanistic and probabilistic explanations.
    For this reason I work on methodology in inference.
    If we then use such models to make decisions, we should explore
    what it means to do so safely.
    <br> 
-->


<!-- this cool <a href="https://pl-ai-seminar.seas.harvard.edu/">seminar on the intersection of AI and PL research</a> -->

<!--
Previously, I was a research assistant and teaching fellow in the Computer Science department at <a href="https://www.seas.harvard.edu/">Harvard SEAS</a>, 
where I worked primarily with <a href="https://www.seltzer.com/margo/">Margo Seltzer</a> and taught primarily for
<a href="https://finale.seas.harvard.edu/">Finale Doshi-Velez</a> and <a href="http://nlp.seas.harvard.edu/rush.html">Sasha Rush</a>. Between Harvard and NYU, I worked
with the <a href="http://cocosci.mit.edu/">CoCoSci</a> group at <a href="https://bcs.mit.edu/">MIT BCS</a> on model-based RL under
<a href="https://cbmm.mit.edu/about/people/tsividis">Pedro Tsividis</a> and <a href="http://cocosci.mit.edu/josh">Josh Tenenbaum</a>.
-->

